{% extends 'main.html' %}
{% block title %}
<div class='display-1'>
    Web Map
</div>
<div class='fs-6 fw-light pb-3'>
    Collect, Analyze, and Visualize data of domains on the internet
</div>
<div class='d-flex mb-3 gap-3 pt-5'>
    <a href='https://github.com/NaolGB/Web-Map'>GitHub repo</a>
    <a href="{% url 'projects_home' %}">Projects</a>
</div>
{% endblock title %}

{% block content %}

<p>
    Aimned at creating a map of the internet, I 
    Visualized the internet through website domain neames and popularity. While the list of websites  
    discovered is continiously updating to discover new websites and update popularity of existing ones, the 
    visualizations currently provided using the top ~100K websites.
    <br><br>
    I used python to crawl through the internet starting from seed domains (domains big enough to serve as a hub).
    To increase efficiency while crawling, I used MySQL with multiprocessing as MySQL can 
    handle mutiple conncetions at a time from different process.
    <br><br>
    The most challenging part of the project was multiprocessing with MySQL and Python. The most commun
    challenge here was facing deadlocks during row updates. I was able to develop a creative solution
    leveraging MySQL and randomization.
    <br><br>
    The data is a continiously growing. Currently only ~1.5 Million websites have been discovered. 
    In addition, some popular websites like are yet to be fully discovered. As 
    such, I am working on addtional crawling and adjusting methods to extract data from more pages to 
    increase the data size and accuracy.
    <br><br>
    You can see my interactive versions in Table Public here and here
</p>

{% endblock content %}